{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc7a0a9",
   "metadata": {},
   "source": [
    "## Standardisation of the data: scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "369616da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8321c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C    Si    Mn      S      P   Ni        Cr        Mo         V  \\\n",
      "0  0.037  0.30  0.65  0.008  0.012  0.0  1.308508  0.541548  0.063321   \n",
      "1  0.037  0.30  0.65  0.008  0.012  0.0  1.308508  0.541548  0.063321   \n",
      "2  0.037  0.30  0.65  0.008  0.012  0.0  1.308508  0.541548  0.063321   \n",
      "3  0.037  0.31  1.03  0.007  0.014  0.0  1.040208  0.461698  0.099845   \n",
      "4  0.037  0.31  1.03  0.007  0.014  0.0  1.040208  0.461698  0.099845   \n",
      "\n",
      "         Cu  ...  AcicularFerrite  Martensite  FerriteCarbide  \\\n",
      "0  0.202337  ...              NaN         NaN             NaN   \n",
      "1  0.202337  ...              NaN         NaN             NaN   \n",
      "2  0.202337  ...              NaN         NaN             NaN   \n",
      "3  0.190271  ...              NaN         NaN             NaN   \n",
      "4  0.190271  ...             40.0         0.0             0.0   \n",
      "\n",
      "                          WeldID  MechanicalTestDone  PrimaryFerrite_missing  \\\n",
      "0    Evans-Ni/CMn-1990/1991-0Aaw                   1                       1   \n",
      "1  Evans-Ni/CMn-1990/1991-0Aawch                   1                       1   \n",
      "2    Evans-Ni/CMn-1990/1991-0Aht                   1                       1   \n",
      "3    Evans-Ni/CMn-1990/1991-0Baw                   1                       1   \n",
      "4  Evans-Ni/CMn-1990/1991-0Bawch                   1                       0   \n",
      "\n",
      "   Ferrite2ndPhase_missing  AcicularFerrite_missing  Martensite_missing  \\\n",
      "0                        1                        1                   1   \n",
      "1                        1                        1                   1   \n",
      "2                        1                        1                   1   \n",
      "3                        1                        1                   1   \n",
      "4                        0                        0                   0   \n",
      "\n",
      "   FerriteCarbide_missing  \n",
      "0                       1  \n",
      "1                       1  \n",
      "2                       1  \n",
      "3                       1  \n",
      "4                       0  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data_imputed_2025_11_05.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9f275dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"C\", \"Si\", \"Mn\", \"S\", \"P\", \"Ni\", \"Cr\", \"Mo\", \"V\", \"Cu\", \"Co\", \"W\",\n",
    "    \"O\", \"Ti\", \"N\", \"Al\", \"B\", \"Nb\", \"Sn\", \"As\", \"Sb\",\n",
    "    \"Current\", \"Voltage\", \"AC_DC\", \"ElectrodePolarity\", \"HeatInput\",\n",
    "    \"InterpassTemp\", \"WeldType\", \"PWHT_Temp\", \"PWHT_Time\",\n",
    "    \"YieldStrength\", \"UTS\", \"Elongation\", \"ReductionArea\",\n",
    "    \"CharpyTemp\", \"CharpyImpact\", \"Hardness\", \"FATT50\", \"PrimaryFerrite\",\n",
    "    \"Ferrite2ndPhase\", \"AcicularFerrite\", \"Martensite\", \"FerriteCarbide\",\n",
    "    \"WeldID\"\n",
    "]\n",
    "\n",
    "chem_cols = ['C', 'Si', 'Mn', 'S', 'P', 'Ni', 'Cr', 'Mo', 'V', 'Cu', 'Co', 'W', 'O','Ti', 'N', 'Al', 'B', 'Nb', 'Sn', 'As', 'Sb']\n",
    "\n",
    "micro_cols = [\n",
    "    'PrimaryFerrite', 'Ferrite2ndPhase', 'AcicularFerrite',\n",
    "    'Martensite', 'FerriteCarbide'\n",
    "]\n",
    "\n",
    "process_param_columns = ['Current', 'Voltage','AC_DC', 'ElectrodePolarity', 'HeatInput', 'InterpassTemp', 'WeldType', 'PWHT_Temp', 'PWHT_Time']\n",
    "\n",
    "mech_cols = [\n",
    "    'UTS', 'Elongation', 'ReductionArea', # Do not include YieldStrength\n",
    "    'CharpyTemp', 'CharpyImpact', 'Hardness', 'FATT50'\n",
    "]\n",
    "\n",
    "process_num = [\"Current\",\"Voltage\",\"HeatInput\",\"InterpassTemp\"]\n",
    "process_cat = [\"AC_DC\",\"ElectrodePolarity\",\"WeldType\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbac0b2",
   "metadata": {},
   "source": [
    "Listing of the columns based on the distribution they are following (see eda for plots). The distributions are going to determine which scaler is used: \n",
    "* StandardScaler: used on data following a Gaussian distribution. \n",
    "* MinMaxScaler : used on bounded data, not following a distribution. \n",
    "* OneHotEncoder : used on categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the columns based on the distribution they are following (see eda for full distributions of each column). The scalers will then be defined based on the different distributions. \n",
    "\n",
    "GAUSSIAN = [\n",
    "    \"C\", \"Si\", \"S\", \"P\", \"V\", \"Co\", \"W\", \"O\", \"N\", \"B\",\"Sn\", \"As\", \n",
    "    \"Sb\", \"UTS\", \"Elongation\", \"ReductionArea\", \"CharpyTemp\", \n",
    "    \"CharpyImpact\", \"Hardness\", \"FATT50\"\n",
    "    ]\n",
    "\n",
    "MINMAX = [\"Mn\", \"Ni\", \"Cr\", \"Mo\", \"Cu\", \"Ti\", \"Al\", \"Nb\",\n",
    "          \"Current\", \"Voltage\", \"PWHT_Temp\", \n",
    "          \"PWHT_Time\", \"PrimaryFerrite\", \"Ferrite2ndPhase\", \"AcicularFerrite\", \n",
    "          \"Martensite\", \"FerriteCarbide\", \"HeatInput\", \"InterpassTemp\"\n",
    "          ]\n",
    "\n",
    "OHE = [\"AC_DC\",\"ElectrodePolarity\",\"WeldType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "69daa3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = chem_cols + process_num + process_cat + micro_cols\n",
    "targets = \"YieldStrength\"\n",
    "\n",
    "x = df[features].copy()\n",
    "y = df[targets].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be11de",
   "metadata": {},
   "source": [
    "Performing a split train/test to avoid any leak during fitting of the scalers.  Parameters: \n",
    "* test_size = 0.2 to keep 80% of the data for learning, while still evaluating the performance of the model in a safe and reliable way. \n",
    "* random_state = 42 to define a standard granularity to make sure splitting is identical at each execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4c6ff6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 47), (1500,), (152, 47), (152,))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separation of labelled and unlabelled data\n",
    "df_labeled = df[df[targets].notna()].copy()\n",
    "df_unlabeled = df[df[targets].isna()].copy()\n",
    "\n",
    "X_labeled = df_labeled.drop(columns=[targets])\n",
    "y_labeled = df_labeled[targets]\n",
    "\n",
    "# Train/test split on labelled data\n",
    "X_train_lab, X_test, y_train_lab, y_test = train_test_split(\n",
    "    X_labeled, y_labeled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Building of the entire train/test set (using unlabelled data as well for the train, and only labelled data for the test)\n",
    "X_train = pd.concat([X_train_lab, df_unlabeled.drop(columns=[targets])], axis=0)\n",
    "y_train = pd.concat([y_train_lab, pd.Series([None]*len(df_unlabeled), index=df_unlabeled.index, name=targets)])\n",
    "\n",
    "# Reindexation\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b9cc9",
   "metadata": {},
   "source": [
    "Definition of the different scaling transformation to perform on each block:\n",
    "* **Chemical composition columns** : MinMaxScaler : the data is bounded and skewed, with a majority of small values (concentrations). MinMaxScaler will bring back those values in the [0;1] interval, without altering the proportions.  \n",
    "* **Process parameters, numerical**: RobustScaler : centered values with the most outliers, RobustScaler centers on the median.  \n",
    "* **Process parameters, categorical**: OneHotEncoder : categorical data is treated and scaled using a categorical scaler, here OneHotEncoder.  \n",
    "* **Microstructure** : MinMaxScaler, for the same reasons as the chemical block : the data is bounded.\n",
    "* **Mechanical data** : StandardScaler : the data derives from controlled physical processes, which tend to disperse the data following a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a993becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Numerical columns (block)\n",
    "# num_chem = [c for c in chem_cols if c in X_train.columns]\n",
    "# num_proc = [c for c in process_num if c in X_train.columns]\n",
    "# num_micro = [c for c in micro_cols if c in X_train.columns]\n",
    "# num_mech = [c for c in mech_cols if c in X_train.columns]\n",
    "\n",
    "# # Categorial columns\n",
    "# cat_proc = [c for c in process_cat if c in X_train.columns]\n",
    "\n",
    "# # Composition of the column transformer\n",
    "# preprocess = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"chem_minmax\", MinMaxScaler(), num_chem),\n",
    "#         (\"proc_robust\", RobustScaler(), num_proc),\n",
    "#         (\"micro_minmax\", MinMaxScaler(), num_micro),\n",
    "#         (\"mech_standard\", StandardScaler(), num_mech),\n",
    "#         (\"proc_ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_proc),\n",
    "#     ],\n",
    "#     remainder=\"drop\"\n",
    "# )\n",
    "\n",
    "gauss = [c for c in GAUSSIAN if c in X_train.columns]\n",
    "minmax = [c for c in MINMAX if c in X_train.columns]\n",
    "ohe = [c for c in OHE if c in X_train.columns]\n",
    "\n",
    "\n",
    "# Composition of the column transformer\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"Gaussian\", StandardScaler(), gauss),\n",
    "        (\"MinMax\", MinMaxScaler(), minmax),\n",
    "        (\"OneHotEncoder\", OneHotEncoder(), ohe)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47025b9f",
   "metadata": {},
   "source": [
    "Creation of a pipeline to fit (on the training set) and then to transform (using train/test) in a reproductible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d2f4028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 54), (152, 54))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocess)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train)\n",
    "\n",
    "X_train_scaled = pipeline.transform(X_train)\n",
    "X_test_scaled  = pipeline.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ca351",
   "metadata": {},
   "source": [
    "Reverting back to a DataFrame after scaling of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "61678140",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1500, 54), indices imply (1500, 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m output_feature_names \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m onehot_feature_names\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mlen\u001b[39m(output_feature_names), X_train_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m X_train_scaled_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_feature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m X_test_scaled_df  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_test_scaled,  index\u001b[38;5;241m=\u001b[39mX_test\u001b[38;5;241m.\u001b[39mindex,  columns\u001b[38;5;241m=\u001b[39moutput_feature_names)\n\u001b[0;32m     20\u001b[0m X_train_scaled_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\marie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:831\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    820\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    821\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    822\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    828\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    829\u001b[0m         )\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 831\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\marie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\marie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (1500, 54), indices imply (1500, 57)"
     ]
    }
   ],
   "source": [
    "output_feature_names = []\n",
    "\n",
    "output_feature_names += gauss\n",
    "output_feature_names += minmax\n",
    "output_feature_names += ohe\n",
    "\n",
    "if len(ohe) > 0:\n",
    "    onehot = pipeline.named_steps[\"preprocess\"].named_transformers_[\"OneHotEncoder\"]\n",
    "    onehot_feature_names = onehot.get_feature_names_out(ohe).tolist()\n",
    "else:\n",
    "    onehot_feature_names = []\n",
    "\n",
    "output_feature_names += onehot_feature_names\n",
    "\n",
    "len(output_feature_names), X_train_scaled.shape[1]\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, index=X_train.index, columns=output_feature_names)\n",
    "X_test_scaled_df  = pd.DataFrame(X_test_scaled,  index=X_test.index,  columns=output_feature_names)\n",
    "\n",
    "X_train_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ed0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train/test\n",
    "train_out = X_train_scaled_df.copy()\n",
    "test_out  = X_test_scaled_df.copy()\n",
    "\n",
    "if y_train is not None:\n",
    "    train_out[targets] = y_train\n",
    "    test_out[targets]  = y_test\n",
    "\n",
    "# Saving the datasets\n",
    "train_out.to_csv(\"../data/train_normalised.csv\", index=False)\n",
    "test_out.to_csv(\"../data/test_normalised.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc7a0a9",
   "metadata": {},
   "source": [
    "## Standardisation of the data: scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369616da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C    Si    Mn      S      P   Ni        Cr        Mo         V  \\\n",
      "0  0.037  0.30  0.65  0.008  0.012  0.0  2.160911  0.611092  0.087085   \n",
      "1  0.037  0.30  0.65  0.008  0.012  0.0  2.160911  0.611092  0.087085   \n",
      "2  0.037  0.30  0.65  0.008  0.012  0.0  2.160911  0.611092  0.087085   \n",
      "3  0.037  0.31  1.03  0.007  0.014  0.0  1.733540  0.497154  0.086635   \n",
      "4  0.037  0.31  1.03  0.007  0.014  0.0  1.733540  0.497154  0.086635   \n",
      "\n",
      "         Cu  ...  CharpyTemp  CharpyImpact  Hardness  FATT50  PrimaryFerrite  \\\n",
      "0  0.191183  ...         NaN           NaN       NaN     NaN             NaN   \n",
      "1  0.191183  ...       -28.0         100.0       NaN     NaN             NaN   \n",
      "2  0.191183  ...       -38.0         100.0       NaN     NaN             NaN   \n",
      "3  0.180019  ...         NaN           NaN       NaN     NaN             NaN   \n",
      "4  0.180019  ...       -48.0         100.0       NaN     NaN            32.0   \n",
      "\n",
      "   Ferrite2ndPhase  AcicularFerrite  Martensite  FerriteCarbide  \\\n",
      "0              NaN              NaN         NaN             NaN   \n",
      "1              NaN              NaN         NaN             NaN   \n",
      "2              NaN              NaN         NaN             NaN   \n",
      "3              NaN              NaN         NaN             NaN   \n",
      "4             28.0             40.0         0.0             0.0   \n",
      "\n",
      "                          WeldID  \n",
      "0    Evans-Ni/CMn-1990/1991-0Aaw  \n",
      "1  Evans-Ni/CMn-1990/1991-0Aawch  \n",
      "2    Evans-Ni/CMn-1990/1991-0Aht  \n",
      "3    Evans-Ni/CMn-1990/1991-0Baw  \n",
      "4  Evans-Ni/CMn-1990/1991-0Bawch  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data_imputed_2025_11_05.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f275dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"C\", \"Si\", \"Mn\", \"S\", \"P\", \"Ni\", \"Cr\", \"Mo\", \"V\", \"Cu\", \"Co\", \"W\",\n",
    "    \"O\", \"Ti\", \"N\", \"Al\", \"B\", \"Nb\", \"Sn\", \"As\", \"Sb\",\n",
    "    \"Current\", \"Voltage\", \"AC_DC\", \"ElectrodePolarity\", \"HeatInput\",\n",
    "    \"InterpassTemp\", \"WeldType\", \"PWHT_Temp\", \"PWHT_Time\",\n",
    "    \"YieldStrength\", \"UTS\", \"Elongation\", \"ReductionArea\",\n",
    "    \"CharpyTemp\", \"CharpyImpact\", \"Hardness\", \"FATT50\", \"PrimaryFerrite\",\n",
    "    \"Ferrite2ndPhase\", \"AcicularFerrite\", \"Martensite\", \"FerriteCarbide\",\n",
    "    \"WeldID\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f35371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_param_columns = ['Current', 'Voltage','AC_DC', 'ElectrodePolarity', 'HeatInput', 'InterpassTemp', 'WeldType', 'PWHT_Temp', 'PWHT_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad04b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_cols = ['C', 'Si', 'Mn', 'S', 'P', 'Ni', 'Cr', 'Mo', 'V', 'Cu', 'Co', 'W', 'O','Ti', 'N', 'Al', 'B', 'Nb', 'Sn', 'As', 'Sb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a7f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mech_cols = [\n",
    "    'YieldStrength', 'UTS', 'Elongation', 'ReductionArea',\n",
    "    'CharpyTemp', 'CharpyImpact', 'Hardness', 'FATT50'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6e38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_cols = [\n",
    "    'PrimaryFerrite', 'Ferrite2ndPhase', 'AcicularFerrite',\n",
    "    'Martensite', 'FerriteCarbide'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff60595",
   "metadata": {},
   "source": [
    "Definition of the different data: differentiation between categorical and numerical data, useful to define which scaling is going to be used on each part.    \n",
    "Definition of the targets and the features to excludes the targets from the scaling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69daa3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_num = [\"Current\",\"Voltage\",\"HeatInput\",\"InterpassTemp\"]\n",
    "process_cat = [\"AC_DC\",\"ElectrodePolarity\",\"WeldType\"]\n",
    "\n",
    "features = chem_cols + process_num + process_cat + micro_cols\n",
    "targets = [\"YieldStrength\",\"UTS\",\"Elongation\",\"ReductionArea\",\"CharpyTemp\",\"CharpyImpact\",\"Hardness\",\"FATT50\"]\n",
    "\n",
    "x = df[features].copy()\n",
    "y = df[targets].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be11de",
   "metadata": {},
   "source": [
    "Performing a split train/test to avoid any leak during fitting of the scalers.  Parameters: \n",
    "* test_size = 0.2 to keep 80% of the data for learning, while still evaluating the performance of the model in a safe and reliable way. \n",
    "* random_state = 42 to define a standard granularity to make sure splitting is identical at each execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c6ff6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1321, 33), (331, 33))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b9cc9",
   "metadata": {},
   "source": [
    "Definition of the different scaling transformation to perform on each block:\n",
    "* **Chemical composition columns** : MinMaxScaler : the data is bounded and skewed, with a majority of small values (concentrations). MinMaxScaler will bring back those values in the [0;1] interval, without altering the proportions.  \n",
    "* **Process parameters, numerical**: RobustScaler : centered values with the most outliers, RobustScaler centers on the median.  \n",
    "* **Process parameters, categorical**: OneHotEncoder : categorical data is treated and scaled using a categorical scaler, here OneHotEncoder.  \n",
    "* **Microstructure** : MinMaxScaler, for the same reasons as the chemical block : the data is bounded.  \n",
    "* **Mechanical data** : StandardScaler : the data derives from controlled physical processes, which tend to disperse the data following a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a993becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns (block)\n",
    "num_chem = [c for c in chem_cols if c in x_train.columns]\n",
    "num_proc = [c for c in process_num if c in x_train.columns]\n",
    "num_micro = [c for c in micro_cols if c in x_train.columns]\n",
    "\n",
    "# Categorial columns\n",
    "cat_proc = [c for c in process_cat if c in x_train.columns]\n",
    "\n",
    "# Composition of the column transformer\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"chem_minmax\", MinMaxScaler(), num_chem),\n",
    "        (\"proc_robust\", RobustScaler(), num_proc),\n",
    "        (\"micro_minmax\", MinMaxScaler(), num_micro),\n",
    "        (\"proc_ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_proc),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728982c",
   "metadata": {},
   "source": [
    "Following errors when defining the pipeline, some outliers had to be re-treated. In the following cell, I look for the columns that contain the outliers I found, and replace them. \n",
    "* I found an interval, and decided to take its middle. \n",
    "* I found 2 values '<1', that I rounded to 0.5 for scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a14eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# I am here looking for values that resemble an interval.\n",
    "\n",
    "# List of numerical columns \n",
    "num_cols = [c for c in x_train.columns if x_train[c].dtype.kind in \"iufc\"]\n",
    "\n",
    "maybe_numeric = [c for c in x_train.columns if x_train[c].dtype == \"object\"]\n",
    "\n",
    "# Looking for a potential interval\n",
    "pattern = re.compile(r\"^\\s*-?\\d+(?:[.,]\\d+)?\\s*[-–]\\s*-?\\d+(?:[.,]\\d+)?\\s*$\")\n",
    "\n",
    "suspects = {}\n",
    "for c in maybe_numeric:\n",
    "    m = x_train[c].astype(str).str.match(pattern, na=False)\n",
    "    if m.any():\n",
    "        suspects[c] = x_train.loc[m, c].unique()[:10]\n",
    "suspects\n",
    "\n",
    "def interval_midpoint(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = s.str.replace(\",\", \".\", regex=False)\n",
    "    ab = s.str.extract(r\"^\\s*(-?\\d+(?:\\.\\d+)?)\\s*[-–]\\s*(-?\\d+(?:\\.\\d+)?)\\s*$\")\n",
    "    mid = ab.astype(float).mean(axis=1)\n",
    "    fallback = pd.to_numeric(s, errors=\"coerce\")\n",
    "    out = mid.fillna(fallback)\n",
    "    return out\n",
    "for c in suspects.keys():\n",
    "    x_train[c] = interval_midpoint(x_train[c])\n",
    "    x_test[c]  = interval_midpoint(x_test[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37401e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am here looking for columns containing a <, and replacing them.\n",
    "suspect_cols = {}\n",
    "\n",
    "for c in x_train.columns:\n",
    "    mask = x_train[c].astype(str).str.contains(\"<\", na=False)\n",
    "    if mask.any():\n",
    "        suspect_cols[c] = x_train.loc[mask, c].unique()[:10]\n",
    "\n",
    "\n",
    "for col in suspect_cols.keys():\n",
    "    mask = x_train[col].astype(str).str.contains(\"<\", na=False)\n",
    "    x_train.loc[mask, col] = 0.5\n",
    "    x_train[col] = pd.to_numeric(x_train[col], errors=\"coerce\")\n",
    "\n",
    "    if col in x_test.columns:\n",
    "        mask_test = x_test[col].astype(str).str.contains(\"<\", na=False)\n",
    "        x_test.loc[mask_test, col] = 0.5\n",
    "        x_test[col] = pd.to_numeric(x_test[col], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47025b9f",
   "metadata": {},
   "source": [
    "Creation of a pipeline to fit (on the training set) and then to transform (using train/test) in a reproductible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2f4028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1321, 45), (331, 45))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocess)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train)\n",
    "\n",
    "X_train_scaled = pipeline.transform(x_train)\n",
    "X_test_scaled  = pipeline.transform(x_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ca351",
   "metadata": {},
   "source": [
    "Reverting back to a DataFrame after scaling of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61678140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mn</th>\n",
       "      <th>S</th>\n",
       "      <th>P</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Mo</th>\n",
       "      <th>V</th>\n",
       "      <th>Cu</th>\n",
       "      <th>...</th>\n",
       "      <th>WeldType_FCA</th>\n",
       "      <th>WeldType_GMAA</th>\n",
       "      <th>WeldType_GTAA</th>\n",
       "      <th>WeldType_MMA</th>\n",
       "      <th>WeldType_NGGMA</th>\n",
       "      <th>WeldType_NGSAW</th>\n",
       "      <th>WeldType_SA</th>\n",
       "      <th>WeldType_SAA</th>\n",
       "      <th>WeldType_ShMA</th>\n",
       "      <th>WeldType_TSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.311258</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.550505</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>0.287541</td>\n",
       "      <td>0.087169</td>\n",
       "      <td>0.353414</td>\n",
       "      <td>0.025465</td>\n",
       "      <td>0.211625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.410596</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.233041</td>\n",
       "      <td>0.890409</td>\n",
       "      <td>0.730539</td>\n",
       "      <td>0.072150</td>\n",
       "      <td>0.311987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.311258</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.550505</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>0.287541</td>\n",
       "      <td>0.087169</td>\n",
       "      <td>0.353414</td>\n",
       "      <td>0.025465</td>\n",
       "      <td>0.211625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>0.298013</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.088710</td>\n",
       "      <td>0.307985</td>\n",
       "      <td>0.266295</td>\n",
       "      <td>0.703043</td>\n",
       "      <td>0.028876</td>\n",
       "      <td>0.268421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.298013</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.580808</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.359333</td>\n",
       "      <td>0.146950</td>\n",
       "      <td>0.321025</td>\n",
       "      <td>0.044662</td>\n",
       "      <td>0.275470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             C        Si        Mn         S         P        Ni        Cr  \\\n",
       "306   0.311258  0.300000  0.550505  0.028777  0.028226  0.287541  0.087169   \n",
       "192   0.410596  0.145455  0.388889  0.043165  0.044355  0.233041  0.890409   \n",
       "309   0.311258  0.300000  0.550505  0.028777  0.028226  0.287541  0.087169   \n",
       "1360  0.298013  0.209091  0.424242  0.057554  0.088710  0.307985  0.266295   \n",
       "63    0.298013  0.254545  0.580808  0.050360  0.020161  0.359333  0.146950   \n",
       "\n",
       "            Mo         V        Cu  ...  WeldType_FCA  WeldType_GMAA  \\\n",
       "306   0.353414  0.025465  0.211625  ...           0.0            0.0   \n",
       "192   0.730539  0.072150  0.311987  ...           0.0            0.0   \n",
       "309   0.353414  0.025465  0.211625  ...           0.0            0.0   \n",
       "1360  0.703043  0.028876  0.268421  ...           1.0            0.0   \n",
       "63    0.321025  0.044662  0.275470  ...           0.0            0.0   \n",
       "\n",
       "      WeldType_GTAA  WeldType_MMA  WeldType_NGGMA  WeldType_NGSAW  \\\n",
       "306             0.0           1.0             0.0             0.0   \n",
       "192             0.0           1.0             0.0             0.0   \n",
       "309             0.0           1.0             0.0             0.0   \n",
       "1360            0.0           0.0             0.0             0.0   \n",
       "63              0.0           1.0             0.0             0.0   \n",
       "\n",
       "      WeldType_SA  WeldType_SAA  WeldType_ShMA  WeldType_TSA  \n",
       "306           0.0           0.0            0.0           0.0  \n",
       "192           0.0           0.0            0.0           0.0  \n",
       "309           0.0           0.0            0.0           0.0  \n",
       "1360          0.0           0.0            0.0           0.0  \n",
       "63            0.0           0.0            0.0           0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_feature_names = []\n",
    "\n",
    "output_feature_names += num_chem\n",
    "output_feature_names += num_proc\n",
    "output_feature_names += num_micro\n",
    "\n",
    "if len(cat_proc) > 0:\n",
    "    onehot = pipeline.named_steps[\"preprocess\"].named_transformers_[\"proc_ohe\"]\n",
    "    onehot_feature_names = onehot.get_feature_names_out(cat_proc).tolist()\n",
    "else:\n",
    "    onehot_feature_names = []\n",
    "\n",
    "output_feature_names += onehot_feature_names\n",
    "\n",
    "len(output_feature_names), X_train_scaled.shape[1]\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, index=x_train.index, columns=output_feature_names)\n",
    "X_test_scaled_df  = pd.DataFrame(X_test_scaled,  index=x_test.index,  columns=output_feature_names)\n",
    "\n",
    "X_train_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729ed0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train/test\n",
    "train_out = X_train_scaled_df.copy()\n",
    "test_out  = X_test_scaled_df.copy()\n",
    "\n",
    "if y_train is not None:\n",
    "    train_out[targets] = y_train\n",
    "    test_out[targets]  = y_test\n",
    "\n",
    "# Saving the datasets\n",
    "train_out.to_csv(\"../data/train_normalised.csv\", index=False)\n",
    "test_out.to_csv(\"../data/test_normalised.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

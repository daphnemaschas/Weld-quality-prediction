{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "# Helper to find latest imputed file\n",
    "imputed_files = sorted(DATA_DIR.glob(\"data_imputed_*.csv\"))\n",
    "if not imputed_files:\n",
    "    raise FileNotFoundError(\"No imputed dataset found in ../data (expected files like data_imputed_YYYY_MM_DD.csv)\")\n",
    "latest_imputed_path = imputed_files[-1]\n",
    "\n",
    "cleaned_path = DATA_DIR / \"cleaned_welddb.csv\"\n",
    "if not cleaned_path.exists():\n",
    "    raise FileNotFoundError(f\"Cleaned dataset not found at {cleaned_path}\")\n",
    "\n",
    "print(f\"Using cleaned dataset: {cleaned_path.name}\")\n",
    "print(f\"Using imputed dataset: {latest_imputed_path.name}\")\n",
    "\n",
    "# Load\n",
    "df_clean = pd.read_csv(cleaned_path)\n",
    "df_imputed = pd.read_csv(latest_imputed_path)\n",
    "\n",
    "# Basic sanity\n",
    "print(df_clean.shape, df_imputed.shape)\n",
    "df_clean.head(2), df_imputed.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fed349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column groups and type detection\n",
    "\n",
    "CHEM_COLS = [\n",
    "    'C', 'Si', 'Mn', 'S', 'P', 'Ni', 'Cr', 'Mo', 'V', 'Cu', 'Co',\n",
    "    'W', 'O', 'Ti', 'N', 'Al', 'B', 'Nb', 'Sn', 'As', 'Sb'\n",
    "]\n",
    "MECH_COLS = [\n",
    "    'YieldStrength', 'UTS', 'Elongation', 'ReductionArea',\n",
    "    'CharpyTemp', 'CharpyImpact', 'Hardness', 'FATT50'\n",
    "]\n",
    "PROC_COLS = [\n",
    "    'Current', 'Voltage', 'AC_DC', 'WireSpeed', 'TravelSpeed', 'HeatInput'\n",
    "]\n",
    "META_COLS = [\n",
    "    'Material', 'Process', 'ShieldingGas', 'Position'\n",
    "]\n",
    "\n",
    "# Keep only present columns per dataset\n",
    "def columns_present(df, cols):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "GROUPS = {\n",
    "    'chemicals': CHEM_COLS,\n",
    "    'mechanical': MECH_COLS,\n",
    "    'process': PROC_COLS,\n",
    "    'metadata': META_COLS,\n",
    "}\n",
    "\n",
    "# Detect types per dataset (categorical vs numeric)\n",
    "def detect_types(df: pd.DataFrame):\n",
    "    # Treat pandas 'category' and low-cardinality objects as categorical\n",
    "    categorical = set(df.select_dtypes(include=['category', 'bool', 'object']).columns)\n",
    "    # Promote low-cardinality objects to categorical\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if df[col].nunique(dropna=True) <= 50:\n",
    "            categorical.add(col)\n",
    "    numeric = set(df.select_dtypes(include=[np.number]).columns)\n",
    "    # Exclude overlap just in case\n",
    "    categorical = list(sorted(categorical - numeric))\n",
    "    numeric = list(sorted(numeric))\n",
    "    return categorical, numeric\n",
    "\n",
    "cat_clean, num_clean = detect_types(df_clean)\n",
    "cat_imputed, num_imputed = detect_types(df_imputed)\n",
    "\n",
    "print(f\"Cleaned: {len(num_clean)} numeric, {len(cat_clean)} categorical\")\n",
    "print(f\"Imputed: {len(num_imputed)} numeric, {len(cat_imputed)} categorical\")\n",
    "\n",
    "# Materialize groups per dataset\n",
    "GROUPS_CLEAN = {k: columns_present(df_clean, v) for k, v in GROUPS.items()}\n",
    "GROUPS_IMPUTED = {k: columns_present(df_imputed, v) for k, v in GROUPS.items()}\n",
    "\n",
    "GROUPS_CLEAN, GROUPS_IMPUTED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting helpers for distributions\n",
    "\n",
    "def plot_numeric_distributions(df: pd.DataFrame, columns: list, title_prefix: str):\n",
    "    cols = [c for c in columns if c in df.columns]\n",
    "    if not cols:\n",
    "        return\n",
    "    n = len(cols)\n",
    "    ncols = 3\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 5, nrows * 4))\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "    for ax, col in zip(axes, cols):\n",
    "        sns.histplot(df[col].dropna(), kde=True, ax=ax)\n",
    "        ax.set_title(col)\n",
    "    for ax in axes[n:]:\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(f\"{title_prefix} - Numeric distributions\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_categorical_distributions(df: pd.DataFrame, columns: list, title_prefix: str, top_k: int = 20):\n",
    "    cols = [c for c in columns if c in df.columns]\n",
    "    if not cols:\n",
    "        return\n",
    "    n = len(cols)\n",
    "    ncols = 3\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 5, nrows * 4))\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "    for ax, col in zip(axes, cols):\n",
    "        counts = df[col].astype(str).value_counts(dropna=False).head(top_k)\n",
    "        sns.barplot(x=counts.values, y=counts.index, ax=ax)\n",
    "        ax.set_title(col)\n",
    "    for ax in axes[n:]:\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(f\"{title_prefix} - Categorical distributions\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run per dataset and group\n",
    "def run_distribution_plots(df: pd.DataFrame, groups: dict, title: str):\n",
    "    categorical, numeric = detect_types(df)\n",
    "    for gname, gcols in groups.items():\n",
    "        num_cols = [c for c in gcols if c in numeric]\n",
    "        cat_cols = [c for c in gcols if c in categorical]\n",
    "        if num_cols:\n",
    "            plot_numeric_distributions(df, num_cols, f\"{title} | {gname}\")\n",
    "        if cat_cols:\n",
    "            plot_categorical_distributions(df, cat_cols, f\"{title} | {gname}\")\n",
    "\n",
    "run_distribution_plots(df_clean, GROUPS_CLEAN, \"Cleaned dataset\")\n",
    "run_distribution_plots(df_imputed, GROUPS_IMPUTED, \"Imputed dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations: numeric (Pearson/Spearman) and categorical (Cramer's V)\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramers_v(confusion_matrix: np.ndarray) -> float:\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt((chi2 / n) / (min(k - 1, r - 1) if min(k - 1, r - 1) > 0 else 1))\n",
    "\n",
    "\n",
    "def categorical_correlation_matrix(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    cols = [c for c in columns if c in df.columns]\n",
    "    if len(cols) < 2:\n",
    "        return pd.DataFrame(index=cols, columns=cols)\n",
    "    mat = pd.DataFrame(index=cols, columns=cols, dtype=float)\n",
    "    for i, c1 in enumerate(cols):\n",
    "        for j, c2 in enumerate(cols):\n",
    "            if j < i:\n",
    "                continue\n",
    "            if c1 == c2:\n",
    "                val = 1.0\n",
    "            else:\n",
    "                tbl = pd.crosstab(df[c1].astype(str), df[c2].astype(str))\n",
    "                if tbl.shape[0] < 2 or tbl.shape[1] < 2:\n",
    "                    val = np.nan\n",
    "                else:\n",
    "                    val = cramers_v(tbl.values)\n",
    "            mat.loc[c1, c2] = val\n",
    "            mat.loc[c2, c1] = val\n",
    "    return mat\n",
    "\n",
    "\n",
    "def plot_corr_heatmap(corr: pd.DataFrame, title: str, cmap: str = \"coolwarm\", vmin: float = -1, vmax: float = 1):\n",
    "    if corr is None or corr.shape[0] == 0:\n",
    "        return\n",
    "    plt.figure(figsize=(max(8, corr.shape[1] * 0.6), max(6, corr.shape[0] * 0.6)))\n",
    "    sns.heatmap(corr, cmap=cmap, vmin=vmin, vmax=vmax, annot=False)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_numeric_correlations(df: pd.DataFrame, groups: dict, title: str):\n",
    "    _, numeric = detect_types(df)\n",
    "    # Global\n",
    "    num_cols = [c for c in numeric if c in df.columns]\n",
    "    if len(num_cols) >= 2:\n",
    "        corr_pearson = df[num_cols].corr(method='pearson')\n",
    "        corr_spearman = df[num_cols].corr(method='spearman')\n",
    "        plot_corr_heatmap(corr_pearson, f\"{title} | Numeric correlations (Pearson)\")\n",
    "        plot_corr_heatmap(corr_spearman, f\"{title} | Numeric correlations (Spearman)\")\n",
    "    # By group\n",
    "    for gname, gcols in groups.items():\n",
    "        gnum = [c for c in gcols if c in num_cols]\n",
    "        if len(gnum) >= 2:\n",
    "            corr_g = df[gnum].corr(method='spearman')\n",
    "            plot_corr_heatmap(corr_g, f\"{title} | {gname} (numeric, Spearman)\")\n",
    "\n",
    "\n",
    "def run_categorical_correlations(df: pd.DataFrame, groups: dict, title: str):\n",
    "    categorical, _ = detect_types(df)\n",
    "    # Global\n",
    "    cat_cols = [c for c in categorical if c in df.columns]\n",
    "    if len(cat_cols) >= 2:\n",
    "        corr_cat = categorical_correlation_matrix(df, cat_cols)\n",
    "        plot_corr_heatmap(corr_cat, f\"{title} | Categorical associations (Cramér's V)\", cmap=\"viridis\", vmin=0, vmax=1)\n",
    "    # By group\n",
    "    for gname, gcols in groups.items():\n",
    "        gcat = [c for c in gcols if c in cat_cols]\n",
    "        if len(gcat) >= 2:\n",
    "            corr_g = categorical_correlation_matrix(df, gcat)\n",
    "            plot_corr_heatmap(corr_g, f\"{title} | {gname} (categorical, Cramér's V)\", cmap=\"viridis\", vmin=0, vmax=1)\n",
    "\n",
    "run_numeric_correlations(df_clean, GROUPS_CLEAN, \"Cleaned dataset\")\n",
    "run_numeric_correlations(df_imputed, GROUPS_IMPUTED, \"Imputed dataset\")\n",
    "\n",
    "run_categorical_correlations(df_clean, GROUPS_CLEAN, \"Cleaned dataset\")\n",
    "run_categorical_correlations(df_imputed, GROUPS_IMPUTED, \"Imputed dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988901e",
   "metadata": {},
   "source": [
    "### Notes de synthèse\n",
    "\n",
    "- Distinctions effectuées:\n",
    "  - Variables numériques vs catégorielles détectées automatiquement (types pandas et cardinalité).\n",
    "  - Groupes de colonnes traités séparément: `chemicals`, `mechanical`, `process`, `metadata`.\n",
    "- Analyses fournies:\n",
    "  - Distributions numériques (histogrammes + KDE) et catégorielles (barplots) par groupe pour les deux jeux (cleaned, imputed).\n",
    "  - Corrélations numériques globales (Pearson/Spearman) et par groupe (Spearman).\n",
    "  - Associations catégorielles globales et par groupe via Cramér's V.\n",
    "- À lire:\n",
    "  - Comparez la dispersion et les modes entre `Cleaned` et `Imputed` pour repérer tout lissage dû à l'imputation (pics plus marqués, queue réduite, etc.).\n",
    "  - Sur les corrélations, vérifiez si l'imputation renforce/affaiblit certaines relations (changement notable des coefficients).\n",
    "  - Pour les catégorielles, des hausses de Cramér's V après imputation peuvent indiquer une structure induite par l'imputation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

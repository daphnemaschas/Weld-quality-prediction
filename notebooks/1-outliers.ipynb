{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3988a23",
   "metadata": {},
   "source": [
    "# Weld Quality Prediction - Exploratory Data Analysis (EDA)\n",
    "## Overview\n",
    "This notebook is the first in a series of notebooks that does the exploratory data analysis and the data preprocessing of this dataset destined to predict the weld quality. \n",
    "The preprocessing is divided in three steps :\n",
    "1. **Oultier handling**: Use domain expertise and IQR strategies to find the outliers in the dataset, and replace them with NaN.\n",
    "2. **Missing values handling**: Use different imputing strategies to fill in the missing values for the useful columns.\n",
    "3. **Standardising and normalising the data**: Apply classic standardisation and normalisation techniques, notably useful for further EDA steps like PCA.\n",
    "4. **Encoding the categorical values**: Three categorical values were detected: AC_DC, ElectrodePolarity and WeldType.\n",
    "\n",
    "Each notebook correspond to a step and is intentionally self contained for readability and modularity purposes. \n",
    "\n",
    "At the end of each data preprocessing notebook, a csv file is generated containing the preprocessing modifications. The next step's notebook starts with the last generated csv.\n",
    "\n",
    "The goal is to predict the yield strength of the weld.\n",
    "\n",
    "\n",
    "# Data preprocessing: Handling outliers\n",
    "The strategy is to first, validate the voltage and current values for each type of welding. These values are well known in domain expertise, and can vary heavily from a weld type to the other, so it makes sense to filter them first based on weld type.\n",
    "\n",
    "Then, we apply an IQR to all the columns, based on the weld type. We made the hypothesis (backed up by domain expertise) that each weld type can have vastly different characteristics and chemical compositions.\n",
    "\n",
    "We also made the hypothesis that the Weld Type column has no errors and can be used reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369616da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb51808",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f275dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"C\", \"Si\", \"Mn\", \"S\", \"P\", \"Ni\", \"Cr\", \"Mo\", \"V\", \"Cu\", \"Co\", \"W\",\n",
    "    \"O\", \"Ti\", \"N\", \"Al\", \"B\", \"Nb\", \"Sn\", \"As\", \"Sb\",\n",
    "    \"Current\", \"Voltage\", \"AC_DC\", \"ElectrodePolarity\", \"HeatInput\",\n",
    "    \"InterpassTemp\", \"WeldType\", \"PWHT_Temp\", \"PWHT_Time\",\n",
    "    \"YieldStrength\", \"UTS\", \"Elongation\", \"ReductionArea\",\n",
    "    \"CharpyTemp\", \"CharpyImpact\", \"Hardness\", \"FATT50\", \"PrimaryFerrite\",\n",
    "    \"Ferrite2ndPhase\", \"AcicularFerrite\", \"Martensite\", \"FerriteCarbide\",\n",
    "    \"WeldID\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00819236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/welddb.data\", delim_whitespace=True, names=columns, na_values='N')\n",
    "print(f\"Dataset loaded with shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e15eb8",
   "metadata": {},
   "source": [
    "## 2. Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb8b9f",
   "metadata": {},
   "source": [
    "#### Missing Data Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c49238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing data percentages\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "missing_percentage = missing_percentage.sort_values(ascending=False).round(2)\n",
    "print(\"Missing data percentages per column (sorted descending):\")\n",
    "pd.DataFrame({'Missing %': missing_percentage})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fd8ea",
   "metadata": {},
   "source": [
    "Some weld types namings are inconsistent in the database. Mainly:\n",
    "1. ShMA and MMA mean the same thing, shielded manual metal arc.\n",
    "2. SMA, SAA and SA mean the same thing, submerged metal arc.\n",
    "\n",
    "We handle this inconsistency by only keeping MMA and SA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize WeldType categorical values\n",
    "def normalize_weld_types(df):\n",
    "    \"\"\"\n",
    "    Normalize inconsistent WeldType values.\n",
    "    - 'ShMA' -> 'MMA' (Shielded Metal Arc)\n",
    "    - 'SMA' -> 'SA' (Submerged Arc)\n",
    "    - 'SAA' -> 'SA' (alternate notation for Submerged Arc)\n",
    "    \"\"\"\n",
    "    if 'WeldType' not in df.columns:\n",
    "        print(\"Warning: 'WeldType' column not found.\")\n",
    "        return df\n",
    "\n",
    "    # Strip whitespace for consistent comparison\n",
    "    weld_series = df['WeldType'].astype(str).str.strip()\n",
    "\n",
    "    # Identify values to replace\n",
    "    mask_shma = df['WeldType'].notna() & weld_series.eq('ShMA')\n",
    "    mask_sma = df['WeldType'].notna() & weld_series.eq('SMA')\n",
    "    mask_saa = df['WeldType'].notna() & weld_series.eq('SAA')\n",
    "\n",
    "    replacements = []\n",
    "    if mask_shma.any():\n",
    "        count = int(mask_shma.sum())\n",
    "        replacements.append(f\"'ShMA' -> 'MMA' ({count} occurrences)\")\n",
    "        df.loc[mask_shma, 'WeldType'] = 'MMA'\n",
    "\n",
    "    if mask_sma.any():\n",
    "        count = int(mask_sma.sum())\n",
    "        replacements.append(f\"'SMA' -> 'SA' ({count} occurrences)\")\n",
    "        df.loc[mask_sma, 'WeldType'] = 'SA'\n",
    "\n",
    "    if mask_saa.any():\n",
    "        count = int(mask_saa.sum())\n",
    "        replacements.append(f\"'SAA' -> 'SA' ({count} occurrences)\")\n",
    "        df.loc[mask_saa, 'WeldType'] = 'SA'\n",
    "\n",
    "    if replacements:\n",
    "        print(\"Applied WeldType normalizations:\")\n",
    "        for rep in replacements:\n",
    "            print(f\"  - {rep}\")\n",
    "    else:\n",
    "        print(\"No WeldType normalizations needed.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply normalization\n",
    "df = normalize_weld_types(df)\n",
    "\n",
    "# Display WeldType distribution\n",
    "print(\"\\nWeldType value counts (excluding NaN):\")\n",
    "weld_counts = df['WeldType'].dropna().astype(str).str.strip().value_counts()\n",
    "display(weld_counts)\n",
    "\n",
    "nan_count = df['WeldType'].isna().sum()\n",
    "print(f\"NaN count in WeldType: {nan_count}\")\n",
    "\n",
    "print(\"\\nUnique WeldType values (sorted):\")\n",
    "unique_welds = sorted(df['WeldType'].dropna().astype(str).str.strip().unique())\n",
    "display(unique_welds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcbf89c",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "### Outlier Handling Strategy\n",
    "**Multi-layered approach for robust data cleaning:**\n",
    "1. **Domain-specific validation**: Check Current/Voltage against welding standards per WeldType.\n",
    "2. **Statistical outlier detection**: Apply IQR method within WeldType groups to handle process-specific distributions.\n",
    "3. **Preservation of data integrity**: Replace outliers with NaN for downstream imputation rather than deletion.\n",
    "\n",
    "This ensures outliers are identified based on both physical constraints and statistical patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878980fe",
   "metadata": {},
   "source": [
    "#### Step 1: Domain-Specific Range Validation\n",
    "Validate Current and Voltage against welding process specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load welding process rules\n",
    "rules_path = '../preprocessing/rules.json'\n",
    "with open(rules_path, 'r') as f:\n",
    "    rules = json.load(f)\n",
    "print(f\"Loaded welding rules for {len(rules)} process types.\")\n",
    "\n",
    "# Validate Current and Voltage per WeldType\n",
    "replaced_count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    wtype = str(row['WeldType']).strip() if pd.notna(row['WeldType']) else None\n",
    "    if wtype in rules:\n",
    "        rule = rules[wtype]\n",
    "        # Validate Current\n",
    "        if 'Current' in rule and pd.notna(row['Current']):\n",
    "            min_val, max_val = rule['Current']['min'], rule['Current']['max']\n",
    "            if not (min_val <= row['Current'] <= max_val):\n",
    "                df.at[idx, 'Current'] = np.nan\n",
    "                replaced_count += 1\n",
    "        # Validate Voltage\n",
    "        if 'Voltage' in rule and pd.notna(row['Voltage']):\n",
    "            min_val, max_val = rule['Voltage']['min'], rule['Voltage']['max']\n",
    "            if not (min_val <= row['Voltage'] <= max_val):\n",
    "                df.at[idx, 'Voltage'] = np.nan\n",
    "                replaced_count += 1\n",
    "print(f\"Domain validation complete: {replaced_count} values replaced with NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr_grouped(df, group_col='WeldType', exclude_cols=None, min_group_size=4):\n",
    "    \"\"\"\n",
    "    Detect and replace outliers using IQR method within groups.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to process\n",
    "    - group_col: Column to group by\n",
    "    - exclude_cols: Columns to exclude from outlier detection\n",
    "    - min_group_size: minimum number of non-NaN samples in a group/column required\n",
    "                      to compute quartiles and apply the IQR rule. Groups/columns\n",
    "                      with fewer samples will be skipped (not considered statistically\n",
    "                      meaningful).\n",
    "\n",
    "    Returns:\n",
    "    - outlier_report: DataFrame with outlier counts per group/column\n",
    "    - previews: List of DataFrames showing before/after samples\n",
    "    \"\"\"\n",
    "    if group_col not in df.columns:\n",
    "        raise ValueError(f\"Grouping column '{group_col}' not found in DataFrame.\")\n",
    "\n",
    "    # Select numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if exclude_cols:\n",
    "        numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "\n",
    "    outlier_records = []\n",
    "    previews = []\n",
    "\n",
    "    # Group by WeldType\n",
    "    weld_series = df[group_col].astype(str).str.strip()\n",
    "    for wtype, group in df.groupby(weld_series):\n",
    "        if wtype.lower() in ('nan', 'none', ''):\n",
    "            continue\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            series = group[col].dropna()\n",
    "            # Skip groups/columns with too few samples to compute quartiles reliably\n",
    "            if series.empty or len(series) < int(min_group_size):\n",
    "                outlier_records.append({'WeldType': wtype, 'column': col, 'outliers_replaced': 0})\n",
    "                continue\n",
    "\n",
    "            q1 = series.quantile(0.25)\n",
    "            q3 = series.quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "\n",
    "            if iqr == 0 or pd.isna(iqr):\n",
    "                outlier_records.append({'WeldType': wtype, 'column': col, 'outliers_replaced': 0})\n",
    "                continue\n",
    "\n",
    "            lower = q1 - 1.5 * iqr\n",
    "            upper = q3 + 1.5 * iqr\n",
    "\n",
    "            # Find outliers in the full DataFrame for this group\n",
    "            mask = (weld_series == wtype) & ((df[col] < lower) | (df[col] > upper))\n",
    "            count = int(mask.sum())\n",
    "            outlier_records.append({'WeldType': wtype, 'column': col, 'outliers_replaced': count})\n",
    "\n",
    "            if count > 0:\n",
    "                # Sample before/after\n",
    "                sample_idx = df.loc[mask].index[:5]\n",
    "                sample_before = df.loc[sample_idx, [col, group_col]].copy().reset_index(drop=True).rename(columns={col: 'before'})\n",
    "                df.loc[mask, col] = np.nan\n",
    "                sample_after = df.loc[sample_idx, [col]].copy().reset_index(drop=True).rename(columns={col: 'after'})\n",
    "                preview = pd.concat([sample_before, sample_after], axis=1)\n",
    "                preview['column'] = col\n",
    "                preview['WeldType_group'] = wtype\n",
    "                previews.append(preview)\n",
    "\n",
    "    outlier_report = pd.DataFrame(outlier_records).set_index(['WeldType', 'column']).sort_values('outliers_replaced', ascending=False)\n",
    "    return outlier_report, previews\n",
    "\n",
    "# Apply outlier detection (use default min_group_size=4; change the argument to adjust behavior)\n",
    "outlier_report, previews = detect_outliers_iqr_grouped(df, exclude_cols=['WeldID'], min_group_size=10)\n",
    "\n",
    "print('Outlier replacements by WeldType and column:')\n",
    "display(outlier_report)\n",
    "\n",
    "if previews:\n",
    "    previews_df = pd.concat(previews, ignore_index=True)\n",
    "    print('\\nSample of changed values (first 50):')\n",
    "    display(previews_df.head(50))\n",
    "else:\n",
    "    print('No outliers detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset summary after preprocessing\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cff321",
   "metadata": {},
   "source": [
    "## 4. Data Visualization\n",
    "### Strategy: Distribution Comparison\n",
    "Visualize pre/post-cleaning distributions for columns with outliers to assess cleaning impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e50c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload original data for comparison\n",
    "df_orig = pd.read_csv(\"../data/welddb.data\", delim_whitespace=True, names=columns, na_values='N')\n",
    "\n",
    "# Compute outlier report on original data (with bug fix)\n",
    "def compute_outlier_report(df, group_col='WeldType', exclude_cols=None):\n",
    "    records = []\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if exclude_cols:\n",
    "        numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "\n",
    "    weld_series = df[group_col].astype(str).str.strip()\n",
    "    for wtype, group in df.groupby(weld_series):\n",
    "        if wtype.lower() in ('nan', 'none', ''):\n",
    "            continue\n",
    "        for col in numeric_cols:\n",
    "            series = group[col].dropna()\n",
    "            if series.empty or len(series) < 4:\n",
    "                records.append({'WeldType': wtype, 'column': col, 'outliers_replaced': 0})\n",
    "                continue\n",
    "            q1 = series.quantile(0.25)\n",
    "            q3 = series.quantile(0.75)\n",
    "            iqr = q3 - q1  # Fixed: was incorrect\n",
    "            if iqr == 0 or pd.isna(iqr):\n",
    "                records.append({'WeldType': wtype, 'column': col, 'outliers_replaced': 0})\n",
    "                continue\n",
    "            lower = q1 - 1.5 * iqr\n",
    "            upper = q3 + 1.5 * iqr\n",
    "            mask = (weld_series == wtype) & ((df[col] < lower) | (df[col] > upper))\n",
    "            records.append({'WeldType': wtype, 'column': col, 'outliers_replaced': int(mask.sum())})\n",
    "    return pd.DataFrame(records).set_index(['WeldType', 'column']).sort_values('outliers_replaced', ascending=False)\n",
    "\n",
    "if 'outlier_report' not in globals() or outlier_report.empty:\n",
    "    outlier_report = compute_outlier_report(df_orig, exclude_cols=['WeldID'])\n",
    "\n",
    "# Get columns with outliers\n",
    "total_by_col = outlier_report.reset_index().groupby('column')['outliers_replaced'].sum().sort_values(ascending=False)\n",
    "cols_with_outliers = total_by_col[total_by_col > 0].index.tolist()\n",
    "\n",
    "if not cols_with_outliers:\n",
    "    print('No columns with outliers to visualize.')\n",
    "else:\n",
    "    print(f\"Visualizing distributions for {len(cols_with_outliers)} columns with outliers...\")\n",
    "    for col in cols_with_outliers:  # Limit to first 5 for brevity\n",
    "        per_weld = outlier_report.reset_index().query(\"column == @col\").sort_values('outliers_replaced', ascending=False)\n",
    "        top_welds = per_weld[per_weld['outliers_replaced'] > 0].head(6)['WeldType'].tolist()\n",
    "\n",
    "        if not top_welds:\n",
    "            continue\n",
    "\n",
    "        # Prepare data for plotting\n",
    "        df_o = df_orig.loc[df_orig['WeldType'].astype(str).str.strip().isin(top_welds), ['WeldType', col]].copy()\n",
    "        df_o = df_o.assign(version='Original').rename(columns={col: 'value'})\n",
    "\n",
    "        df_c = df.loc[df['WeldType'].astype(str).str.strip().isin(top_welds), ['WeldType', col]].copy()\n",
    "        df_c = df_c.assign(version='Cleaned').rename(columns={col: 'value'})\n",
    "\n",
    "        plot_df = pd.concat([df_o, df_c], ignore_index=True)\n",
    "        plot_df['WeldType'] = plot_df['WeldType'].astype(str).str.strip()\n",
    "\n",
    "        plt.figure(figsize=(max(8, len(top_welds) * 1.2), 6))\n",
    "        sns.boxplot(x='WeldType', y='value', hue='version', data=plot_df, showfliers=True)\n",
    "        plt.title(f\"{col} â€” Total outliers: {int(total_by_col.loc[col])}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91891d",
   "metadata": {},
   "source": [
    "## 5. Data Export\n",
    "### Strategy: Preserve Cleaned Dataset\n",
    "Save the processed dataset for modeling while maintaining data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Display full DataFrame (use with caution on large datasets)\n",
    "# Uncomment the following to view the entire cleaned dataset\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 2000):\n",
    "#     display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned dataset\n",
    "output_path = '../data/cleaned_welddb.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Cleaned dataset exported to: {output_path}\")\n",
    "print(f\"ðŸ“Š Final shape: {df.shape}\")\n",
    "print(\"ðŸŽ¯ Ready for the next step!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
